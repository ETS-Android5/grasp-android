Stages:

stage 0: logging events

stage 1: the screen can be split with straight lines
spanning from one side to another

stage 2: the screen splits can be resized and discarded

stage 3: expressions can be edited with touch (e.g. they
can be moved from one view to another);

stage 4: lisp files can be imported and exported

stage 5: atom editing and basic gestutes:
- box
- underscore

  box -> list

  underscore -> atom

stage 6: 
- expressions can be evaluated (port to Kawa)
(change the internal representation to use cons cells?)
- undoing and history tracking
- gesture framework
- support for cursors within expressions and keyboard editing

stage 7: interaction extension mechanism: certain kinds
of expressions can be interpreted visually. an example:
A* on graphs

stage 8: expressions can be pinned (context menu) and maximized
(double tap). a pinned expression interprets touch
actions in its own way. APKs can be generated. Support for
module ecosystem (via network)

misc:

  vertical bar -> comment / dotted tail

  Q - magnifying glass

  straight line between two editors - start targets end

